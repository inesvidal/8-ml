plot(hClustering)
myplclust <- function( hclust, lab=hclust$labels, lab.col=rep(1,length(hclust$labels)), hang=0.1,...){
## modifiction of plclust for plotting hclust objects *in colour*!
## Copyright Eva KF Chan 2009
## Arguments:
##    hclust:    hclust object
##    lab:        a character vector of labels of the leaves of the tree
##    lab.col:    colour for the labels; NA=default device foreground colour
##    hang:     as in hclust & plclust
## Side effect:
##    A display of hierarchical cluster with coloured leaf labels.
y <- rep(hclust$height,2); x <- as.numeric(hclust$merge)
y <- y[which(x<0)]; x <- x[which(x<0)]; x <- abs(x)
y <- y[order(x)]; x <- x[order(x)]
plot( hclust, labels=FALSE, hang=hang, ... )
text( x=x, y=y[hclust$order]-(max(hclust$height)*hang),
labels=lab[hclust$order], col=lab.col[hclust$order],
srt=90, adj=c(1,0.5), xpd=NA, ... )
}
dataFrame <- data.frame(x=x,y=y)
distxy <- dist(dataFrame)
hClustering <- hclust(distxy)
myplclust(hClustering,lab=rep(1:3,each=4),lab.col=rep(1:3,each=4))
dataFrame <- data.frame(x=x,y=y)
par(mar=rep(0.1,4))
plot(x,y,col="blue",pch=19,cex=2)
points(x[8],y[8],col="orange",pch=3,lwd=3,cex=3)
points(x[1],y[1],col="orange",pch=3,lwd=3,cex=3)
segments(x[8],y[8],x[1],y[1],lwd=3,col="orange")
dataFrame <- data.frame(x=x,y=y)
par(mar=rep(0.1,4))
plot(x,y,col="blue",pch=19,cex=2)
points(mean(x[1:4]),mean(y[1:4]),col="orange",pch=3,lwd=3,cex=3)
points(mean(x[5:8]),mean(y[5:8]),col="orange",pch=3,lwd=3,cex=3)
segments(mean(x[1:4]),mean(y[1:4]),mean(x[5:8]),mean(y[5:8]),lwd=3,col="orange")
dataFrame <- data.frame(x=x,y=y)
set.seed(143)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
heatmap(dataMatrix)
dataFrame <- data.frame(x=x,y=y)
set.seed(143)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
heatmap(dataMatrix)
set.seed(1234); par(mar=c(0,0,0,0))
x <- rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y <- rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
dataFrame <- data.frame(x=x,y=y)
set.seed(143)
dataMatrix <- as.matrix(dataFrame)[sample(1:12),]
heatmap(dataMatrix)
require(UsingR)
data(mtcars)
summary(mtcars)
mtcars
?mtcars
install.packages("enet")
install.packages("AppliedPredictiveModeling")
install.packages("caret")
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("gbm")
install.packages("lubridate")
install.packages("forecast")
install.packages("e1071")
install.packages("randomForest")
install.packages("lars")
install.packages("elasticnet")
install.packages("pander")
install.packages("xtable")
install.packages("dplyr")
library(knitr)
?read.csv
library(knitr)
library(caret)
library(randomForest)
setwd("~/Coursera/8-ml/ml-project")
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename_train <- "pml-training.csv"
filename_test <- "pml-testing.csv"
if (!file.exists(filename_train)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_train, method = "curl")
date_downloaded <- date()
}
if (!file.exists(filename_test)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_test, method = "curl")
date_downloaded <- date()
}
#opening the data
train <- read.csv(filename_train)
test <- read.csv(filename_test)
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename_train <- "pml-training.csv"
filename_test <- "pml-testing.csv"
if (!file.exists(filename_train)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_train, method = "curl")
date_downloaded <- date()
}
if (!file.exists(filename_test)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_test, method = "curl")
date_downloaded <- date()
}
#opening the data
train <- read.csv(filename_train)
test <- read.csv(filename_test)
download.file
?download.file
download.file(url_test, filename_train, method = "auto", cacheOK = FALSE)
download.file(url_test, filename_train, method = "curl", cacheOK = FALSE)
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename_train <- "pml-training.csv"
filename_test <- "pml-testing.csv"
if (!file.exists(filename_train)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_train, method = "curl", cacheOK = FALSE)
date_downloaded <- date()
}
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename_train <- "pml-training.csv"
filename_test <- "pml-testing.csv"
if (!file.exists(filename_train)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_train, filename_train, method = "curl", cacheOK = FALSE)
date_downloaded <- date()
}
if (!file.exists(filename_test)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_test, method = "curl")
date_downloaded <- date()
}
#opening the data
train <- read.csv(filename_train)
test <- read.csv(filename_test)
train$classe
## Data exploratoration
createDataPartition
?createDataPartition
20/19622
install.packages("doMC")
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename_train <- "pml-training.csv"
filename_test <- "pml-testing.csv"
if (!file.exists(filename_train)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_train, filename_train, method = "curl", cacheOK = FALSE)
date_downloaded <- date()
}
if (!file.exists(filename_test)) {
print("INFO: csv file not found")
### Getting the dataset, and unzipping the files
download.file(url_test, filename_test, method = "curl")
date_downloaded <- date()
}
#opening the data
training <- read.csv(filename_train)
testing <- read.csv(filename_test)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.999,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
pr<-prcomp(train)
pr
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.998,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.999,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.999,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.9995,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.9999,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
inTrain <- createDataPartition(y=train$classe, times = 1, p=0.99999,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
dim(train)
dim(test)
dim(validate)
20/19622
1-20/19622
tree <- train(classe ~., method ="rpart", data = train)
install.packages("rattle")
install.packages("rpart")
install.packages("rpart")
install.packages("RGtk2")
library(RGtk2)
library(RGtk2)
install.packages("YaleToolkit")
?whatis
library(YaleToolkit)
?whatis
whatis(train)
head(train$new_window)
whatis(train[train$new_window =yes])
whatis(train[train$new_window =yes,])
whatis(train[train$new_window == yes,])
whatis(train[train$new_window == "yes",])
cor(train[train$new_window == "yes",], train[train$new_window == "no",])
summary(train[train$new_window == "yes",]$var_accel_dumbbell)
summary(train[train$new_window == "no",]$var_accel_dumbbell)
?complete_cases
??complete_cases
?complete.cases
complete.cases(tr)
complete.cases(tx)
complete.cases(train)
160-sum(complete.cases(train))
sum(complete.cases(train))
dim(train)
dim(complete.cases(train))
length(complete.cases(train))
head(whatis(cl_training))
irr_rows <- complete.cases(training)
cl_training <- training[-irr_rows,]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. all NAs
head(whatis(cl_training))
whatis(cl_training)
19215/19621
whatis(cl_training[cl_training$ == "yes",])
whatis(cl_training[cl_training$new_window == "yes",])
head(whatis(cl_training[cl_training$new_window == "yes",]))
head(whatis(cl_training))
head(cl_training)
head(cl_training[cl_training$new_window == "yes",])
head(cl_training$X)
head(cl_training[cl_training$new_window == "yes",]$X)
head(cl_training$X)
head(cl_training[cl_training$new_window == "no",]$X)
irr_rows <- complete.cases(training)
cl_training <- training[-irr_rows,]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% NAs, there are some columns that are always NA when the variable new_window = "no"
head(whatis(cl_training[cl_training$new_window == "no",]))
head(whatis(cl_training))
head(cl_training$X)
head(cl_training[cl_training$new_window == "no",]$X)
cl_training <- cl_training[, colSums(is.na(cl_training))/nrow(cl_training) < .95]
dim(training)
dim(cl_training)
View(cl_training)
irr_rows <- complete.cases(training)
training_cl1 <- training[-irr_rows,]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% NAs, there are some columns that are always NA when the variable new_window = "no"
#head(whatis(cl_training[cl_training$new_window == "no",]))
#head(whatis(cl_training))
#head(cl_training$X)
#head(cl_training[cl_training$new_window == "no",]$X)
training_cl2 <- training_cl1[, colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
dim(training)
dim(training_cl1)
dim(training_cl2)
sum(complete.cases(training))
?complete.cases
training_cl1 <- training[!complete.cases(training),]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% NAs, there are some columns that are always NA when the variable new_window = "no"
#head(whatis(cl_training[cl_training$new_window == "no",]))
#head(whatis(cl_training))
#head(cl_training$X)
#head(cl_training[cl_training$new_window == "no",]$X)
training_cl2 <- training_cl1[, colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
dim(training)
dim(training_cl1)
dim(training_cl2)
View(cl_training)
colnames(colSums(is.na(training_cl1))/nrow(training_cl1) < .95)[colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
colnames(training_cl1)[colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
dim(colnames(training_cl1)[colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
length(colnames(training_cl1)[colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
# Cleaning the dataset to remove irelevant observations (rows), e.g. all NAs
training_cl1 <- training[!complete.cases(training),]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% NAs, there are some columns that are always NA when the variable new_window = "no"
#head(whatis(cl_training[cl_training$new_window == "no",]))
#head(whatis(cl_training))
#head(cl_training$X)
#head(cl_training[cl_training$new_window == "no",]$X)
training_cl2 <- training_cl1[, - colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
length(colnames(training_cl1)[colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
dim(training)
dim(training_cl1)
dim(training_cl2)
View(cl_training)
length(colnames(training_cl1)[-colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
length(colnames(training_cl1)[!colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
length(colnames(training_cl1)[!colSums(is.na(training_cl1))/nrow(training_cl1) < .80])
whatis(cl_training_cl2)
training_cl1 <- training[!complete.cases(training),]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% NAs, there are some columns that are always NA when the variable new_window = "no"
#head(whatis(cl_training[cl_training$new_window == "no",]))
#head(whatis(cl_training))
#head(cl_training$X)
#head(cl_training[cl_training$new_window == "no",]$X)
training_cl2 <- training_cl1[, colSums(is.na(training_cl1))/nrow(training_cl1) < .95]
length(colnames(training_cl1)[!colSums(is.na(training_cl1))/nrow(training_cl1) < .95])
whatis(cl_training_cl2)
dim(training)
dim(training_cl1)
dim(training_cl2)
whatis(training_cl2)
View(cl_training)
is.na
?is.na
?is.blank
training_cl2 <- training_cl1[training_cl1 == ""] <- NA
training_cl3 <- training_cl2[, colSums(is.na(training_cl2))/nrow(training_cl2) < .95]
dim(training)
dim(training_cl1)
dim(training_cl2)
dim(training_cl3)
training_cl2 <- training_cl1[training_cl1 == ""] <- NA
training_cl3 <- training_cl2[, colSums(is.na(training_cl2))/nrow(training_cl2) < .95]
training_cl2 <- training_cl1
training_cl2[training_cl2 == ""] <- NA
training_cl3 <- training_cl2[, colSums(is.na(training_cl2))/nrow(training_cl2) < .95]
dim(training)
dim(training_cl1)
dim(training_cl2)
dim(training_cl3)
View(cl_training3)
View(training_cl3)
# Creating working sets
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(trainning_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", Train set", "Test set","Validate set"))),
caption ="Original datasets",
auto = TRUE)
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(trainning_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(trainning_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
library(knitr)
library(xtable)
library(markdown)
library(rmarkdown)
library(ggplot2)
library(pander)
library(knitr)
library(caret)
library(randomForest)
library(doMC)
library(rpart)
library(rattle)
registerDoMC(cores = 5)
setwd("~/Coursera/8-ml/ml-project")
opts_chunk$set(echo = TRUE, cache = TRUE)
registerDoMC(cores = 4)
# Cleaning the dataset to remove irelevant observations (rows), e.g. all NAs
training_cl1 <- training[!complete.cases(training),]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% blanks or NAs, there are some columns that are always NA when the variable new_window = "no"
training_cl2 <- training_cl1
training_cl2[training_cl2 == ""] <- NA
training_cl3 <- training_cl2[, colSums(is.na(training_cl2))/nrow(training_cl2) < .95]
dim(training)
dim(training_cl1)
dim(training_cl2)
dim(training_cl3)
View(training_cl3)
# Creating working sets
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(trainning_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
# Prediction study design
# predicting the classe of exercise being performed (classe column)
# Cleaning the dataset to remove irelevant observations (rows), e.g. all NAs
training_cl1 <- training[!complete.cases(training),]
# Cleaning the dataset to remove irrelevant variables (columns), e.g. < 97% blanks or NAs, there are some columns that are always NA when the variable new_window = "no"
training_cl2 <- training_cl1
training_cl2[training_cl2 == ""] <- NA
training_cl3 <- training_cl2[, colSums(is.na(training_cl2))/nrow(training_cl2) < .95]
# Creating working sets
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.99,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(training_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.998,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(training_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.9989,list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(training_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
inTrain <- createDataPartition(y=training_cl3$classe, times = 1, p=0.998,list = FALSE)
train <- training_cl3[inTrain,]
test <- training_cl3[-inTrain,]
validate <- testing
table1 <- xtable(
matrix(c(dim(training), dim(testing), dim(training_cl3), dim(train), dim(test), dim(validate)),
ncol = 6, byrow = FALSE,
dimnames = list(c("Observations", "Variables"), c("Original training dataset", "Original testing","Clean Training dataset", "Train set", "Test set","Validate set"))),
caption = "Original datasets",
auto = TRUE)
#align = c("lll|lll"))
panderOptions('table.split.table', Inf)
pander(table1)
?select
library(dplyr)
?select
